# Deloppgave 3: Vitenskapsfilosofi

<!-- Part 3: Philosophy of science -->

## 1. Falsifikasjonisme

Poppers falsifiserbarhetskriterium er enkelt forklart at vitenskapelige teorier må kunne falsifiseres, altså motbevises, for å kunne kategoriseres som vitenskapelige. Bakgrunnen for dette er at oppfatningen av et sterkt induktivt argument ikke stemmer, og at deduksjon er argumentet som burde brukes i vitenskap (Popper, 1969). Vitenskapelige teorier skal ifølge Popper altså ikke underbygges av data, blant annet fordi man da kan modifisere en teori for å få den til å stemme med dataene. Dermed kan man alltid justere teorien etter dataene slik at den blir nærmest umulig å tilbakevise. Om en teori ikke er falsifiserbar, altså ikke kan tilbakevises, er den uvitenskapelig ifølge Popper, også kjent som pseudovitenskap. Okasha og andre vitenskapsfilosofer er uenig i Poppers syn, og mener at en sterk vitenskapelig teori trenger bekreftelse, noe som krever induktive argumenter. Eksempelvis tester kanskje forskere en teori gjennom en studie eller eksperiment, men hvis dataene her gir grunnlag for å endre eller modifisere hypotesen, er det kanskje nettopp det som behøves for å gjøre videre fremskritt. Et eksempel på dette er Adams og Leverriers oppdagelse av Uranus, som tok utgangspunkt i Newtons teorier. De fant senere ut at den ikke var helt korrekt på et område, som igjen førte til oppdagelsen av en ny planet (Okasha, 2016). Ifølge Popper er dette pseudovitenskap, mens Okasha mener dette i høyeste grad er vitenskap. Det legges mer vekt på hvor godt en teori er bekreftet, og skille mellom hva som er vitenskapelig og ikke lagt like mye vekt på. Selv om både Popper og Okasha har flere gode argumenter for sine syn, må jeg nok si meg mest enig med Okasha. For det første vil det være svært vanskelig å komme utenom induktiv metode i forskning på veldig mange områder. I et perfekt scenario hadde utelukkende bruk av deduktiv metode vært det beste, da konklusjonen er garantert og risikoen for feil liten. Men i realiteten er det vanskelig å unnvike induktivismen helt og holdent. Det ville også vært uheldig om forskere måtte forkaste alle teorier hvis den ble motbevist i et tilfelle, mens den er bekreftet i x-antall andre tilfeller. Her har man jo også eksempelvis meta-analyser som sammenfatter forskning og studier på et område, viser hovedtrekkene og luker ut de svakeste studiene. Hvis vitenskapen har rom for å være oppdagende, gir det også rom for nye oppdagelser, selv om teorien som var utgangspunktet ikke var helt korrekt på alle områder.

## 2. HD-metoden og abduksjon/Bayesianisme

Strukturen på et bekreftende vitenskapelig argument ifølge den hypotetisk deduktive metoden (HD-metoden) er delt inn i en oppdagende- og en begrunnende del. Den oppdagende delen kan betegnes som en kvalifisert gjetning, og ifølge Hempel som sto bak metoden, er det ikke noen rett eller gal måte å gjøre dette på. Dette begrenses bare av vitenskapsmenns oppfinnsomhet og fantasi, og det det trengs ingen videre argumenter eller begrunnelse i dette stadiet [@dellsen_vitenskapsfilosofi_2022]. Men, for at en teori skal være mer enn en kvalifisert gjetning, kreves det en begrunnende del. Teorien, eller hypotesen, må utlede noen empiriske konsekvenser som kan bekrefte (eller avkrefte) teorien (Hempel, 1966). Et eksempel på dette kan være hypotesen om at to terskeløkter på samme dag gir bedre anaerob laktatterskel enn en terskeløkt om dagen. Ut fra dette kan man dedusere empiriske konsekvenser, som igjen kan etterprøves. I dette eksempelet vil de empiriske konsekvensene være at utøveren får en høyere terskelfart, lavere laktat på samme belastning sammenlignet med før studien og høyere fart på samme laktatverdi. Bekreftes disse, bekreftes teorien induktivt, til en viss grad. Den kan ikke garantere at teorien stemmer grunnet at den er bekreftet induktivt, men jo mer eller fler empiriske konsekvenser som bygger opp under teorier, jo sterke er teorien bekreftet. I praksis deler vi inn HD-metoden i 4 trinn (Hempel, 1966). Trinn 1 er å formulere hypotesen, som nevnt tidligere en kvalifisert gjetning. Trinn 2 er å utlede de empiriske konsekvensene som medfølger teorien, som altså må stemme om teorien skal være sann. I trinn 3 må man teste og etterprøve de empiriske konsekvensene, som oftest gjennom en studie eller et eksperiment. Trinn 4 er der man eventuelt får den induktive bekreftelsen. Viser det seg at de empiriske konsekvensene stemmer, bekreftes teorien induktivt til en viss grad. Abduksjon er en annen form for vitenskapelig bekreftelse som er ment for å løse svakhetene til HD-metoden, også kjent som slutningen til den beste forklaringen [@dellsen_vitenskapsfilosofi_2022]. Her sammenlignes ulike teorier som skal forklare relevante data, der den beste teorien velges. Kriterier som legges vekt på i abduksjon er forklaringskraft og enkelhet. Med forklaringskraft menes hvor godt teorien forklarer dataene, i likhet med HD-metoden. En teori må kunne forklare eksempelvis et fenomen bedre enn andre teorier. Men fins det flere teorier som har lik forklaringskraft, er det den enkleste teorien som foretrekkes i abduksjon. I praksis betyr dette at hvis to teorier forklarer empiriske data like godt, er det den enkleste teorien som er den beste. Denne tankegangen baserer seg på ideen fra William Ockham, og den såkalte Ockhams barberkniv. Ockhams barberkniv går ut på at unødvendige momenter i en forklaring elimineres (Dellsén, 2022). Fordelen med dette er at unødvendige momenter i en forklaringsmodell kan ha en høyere sannsynlighet for å være feil, nettopp fordi de er unødvendige.

## 3. Replikasjonskrisen

Alexander Bird mener at basefrekvensfeilen (The base rate fallacy) er årsaken til at mange resultat i noen vitenskaper ikke repliseres. Basefrekvensfeilen oppstår ofte i scenarioer der sannsynlighet for visse fenomener er inne i bildet, som følge av at forskere fokuserer ensporet på tilstedeværelsen av bevis og neglisjerer sannsynligheten for at fenomenet ville oppstå uten beviset (Bird, 2021). Dette fører, ifølge Bird, til feilaktige konklusjoner da bevisene er sterke, men feilaktig korrelert med forekomsten. Bird bruker eksempler der sannsynligheten for å ha f. eks en sykdom er lav, eksempelvis 0,01%, og at testen for å påvise sykdommen er 95% sikker. Hvis man da tester positivt skulle man kanskje ved første øyekast si at det er 95% sannsynlighet for at personen har sykdommen, men sannheten er faktisk at sannsynligheten for at personen som testet positivt faktisk har sykdommen er 1,9%. Dette fordi sannsynligheten for å få et falskt positivt svar er mye høyere enn et korrekt positivt svar når sykdommen er så sjelden som 0,01% (Bird, 2021). Hvordan basefrekvensfeilen fører til replikasjonskrisen ifølge Bird er ved at mange hypoteser som klassifiseres som riktige gjennom forskningen er falske positive (type-1 feil). I tillegg trekker Bird fram et poeng om at den statistiske signifikansen holder et for lavt nivå. Hvis vi for eksempel tar utgangspunkt i at 90% av testede hypoteser er usanne, er basefrekvensen til de sanne hypotesene så lav som 10%. Birds analyser baserer seg i stor grad på Bayesiansk sannsynlighetsregning. I mange forskningsfelt er 0,05 satt som P-verdi for statistisk signifikans (Bird, 2021), og kan enkelt forklart sies å være sannsynligheten for å få type-1 feil. Statistisk styrke er derimot sannsynligheten for å ikke få et falskt negativt resultat, type-2 feil \[@dellsen_vitenskapsfilosofi_2022\]. Kravet til statistisk signifikans er ofte satt til 80%. Regner vi ut sannsynligheten for eksempelet over er sannsynligheten for statistisk signifikans kun 64%. Altså kan replikasjonskrisen forklares som en kombinasjon av at flertallet av hypotesene er usanne kombinert med at kravet til statistisk signifikans er for lavt. I sin artikkel diskuterer også Bird flere andre mulige forklaringer på replikasjonskrisen. Blant disse finner vi lav statistisk styrke, tvilsomme forskningspraksiser, at negative resultater ikke publiseres, dårlige incentiver og til og med forskningsjuks (Bird, 2021). At lav statistisk styrke, som gir større rom for type-2 feil er forklaringen, er Bird uenig i. Han peker på at problemet ikke forsvinner selv om man øker den statiske styrken, som i eksempelet i forrige avsnitt. Med tvilsomme forskningspraksiser mener Bird fabrikkering og/eller falsifisering av data, f. eks manipulering av P-verdier. Han anerkjenner at problemet eksisterer, men stiller likevel spørsmålstegn ved hvor stor grad dette kan være årsaken til falske positive hypoteser og replikasjonskrisen. Det finnes bevis, men ikke tilstrekkelig til å trekke en tydelig konklusjon (Bird, 2021). Det kan også være andre ting som ikke er direkte fusk med dataene, men eksempelvis små studier med få forsøkspersoner som gir lav statistisk styrke \[@dellsen_vitenskapsfilosofi_2022\], noe som gjør at resultatet er mindre reproduserbart enn ved større studier med flere forsøkspersoner. Det er også en skeivfordeling mellom andelen positive og negative resultat som publiseres, og andelen av publisert forskning har en overvekt av positive funn. Dette er kanskje ikke så rart ettersom det er det man ønsker å finne, men dette kan bidra til å gi et falskt bilde på virkeligheten. Et negativt resultat er også et resultat, og når dette ikke publiseres kan det være med å bygge opp under den såkalte replikasjonskrisen. Jeg mener Bird argumenterer godt for sitt synspunkt på replikasjonskrisen, og er i mer eller mindre grad enig med han. Årsakene til at studier mislykkes å repliseres synes å være forårsaket av basefrekvensfeil heller enn at studiene var feil eller dårlig gjennomført (Bird, 2021). I tillegg legger han ikke skjul på at andre mulige forklaringer også spiller en rolle, men presiserer samtidig tydelig at disse i seg selv ikke gir en tilstrekkelig forklaring. Men på en annen side, er det også noen gode argumenter som taler imot. Spesielt når det gjelder at lav statistisk styrke ser det kanskje ut til at P-grenseverdi på 0.05 er betryggende, mens mange mener den burde være betydelig lavere. Selv er Bird åpen for at den kanskje burde vært så lav som 0.005 på flere forskningsfelt. Størrelsen på studier trekkes også fram til en årsak for replikasjonskrisen, noe begge sider av debatten virker å anerkjenne. Om Bird har rett i at hans forklaring er bedre er vanskelig å kunne si helt sikkert, men argumentene underbygges godt og han neglisjerer ikke argumentene til den andre siden. Jeg vil derfor kunne påstå at hans forklaring er bedre.
